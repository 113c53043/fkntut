import sys
import os
import argparse
import torch
import numpy as np
import hashlib
from omegaconf import OmegaConf
from torch import autocast
from PIL import Image
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad
from torch.nn import functional as F

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(CURRENT_DIR)

try:
    from ldm.util import instantiate_from_config
    from ldm.models.diffusion.dpm_solver import DPMSolverSampler
except ImportError:
    pass

def load_model_from_config(config, ckpt, device):
    print(f"Loading model from {ckpt}...")
    pl_sd = torch.load(ckpt, map_location="cpu", weights_only=False)
    sd = pl_sd["state_dict"]
    model = instantiate_from_config(config.model)
    m, u = model.load_state_dict(sd, strict=False)
    model.to(device)
    model.eval()
    return model

def get_secret_message(payload_path, secret_key, capacity_bits):
    """æº–å‚™åŠ å¯†çš„ç§˜å¯†è¨Šæ¯ bitsï¼Œä¸¦åŠ å…¥å®¹éŒ¯æ¨™é ­"""
    if not os.path.exists(payload_path):
        with open(payload_path, "wb") as f:
            f.write(os.urandom(600))
            
    with open(payload_path, "rb") as f: 
        raw_data = f.read()

    # AES åŠ å¯†
    aes_key = hashlib.sha256(str(secret_key).encode()).digest()
    cipher = AES.new(aes_key, AES.MODE_ECB)
    encrypted_data = cipher.encrypt(pad(raw_data, AES.block_size))
    
    # Header Repetition (é‡è¤‡ 3 æ¬¡)
    length_val = len(encrypted_data)
    length_bytes = length_val.to_bytes(2, 'big')
    final_payload = length_bytes * 3 + encrypted_data
    
    print(f"ğŸ“¦ Payload created: {len(encrypted_data)} bytes data + 6 bytes header (Repeated 3x)")
    
    # è½‰æˆ bits array
    bits = np.unpackbits(np.frombuffer(final_payload, dtype=np.uint8))
    
    # æˆªæ–·æˆ–å¡«å……
    if len(bits) > capacity_bits:
        bits = bits[:capacity_bits]
    else:
        padding = np.random.randint(0, 2, capacity_bits - len(bits))
        bits = np.concatenate([bits, padding])
        
    return torch.from_numpy(bits).float()

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--prompt", type=str, default="A cute cat sitting on a desk, 8k, high quality")
    parser.add_argument("--secret_key", type=int, default=123456)
    parser.add_argument("--payload_path", type=str, default="payload.dat")
    parser.add_argument("--outpath", type=str, default="stego_opt.png")
    parser.add_argument("--ckpt", type=str, default="weights/v1-5-pruned.ckpt")
    parser.add_argument("--config", type=str, default="configs/stable-diffusion/ldm.yaml")
    parser.add_argument("--device", type=str, default="cuda")
    
    # === åƒæ•¸ä¿®æ­£ ===
    # 300 æ­¥é€šå¸¸è¶³å¤ ï¼Œè‹¥é¡¯å¡å¤ å¿«å¯åŠ åˆ° 500
    parser.add_argument("--opt_iters", type=int, default=300)
    parser.add_argument("--lr", type=float, default=0.01)
    
    # æ¬Šé‡å¹³è¡¡ï¼š
    # lambda_img=5.0: ä¿æŒç•«è³ªï¼Œä½†å…è¨±å¾®å°è®Šå‹•
    # lambda_msg=20.0: å¼·åˆ¶è¨Šæ¯å¯«å…¥
    parser.add_argument("--lambda_img", type=float, default=5.0) 
    parser.add_argument("--lambda_msg", type=float, default=20.0)
    
    opt = parser.parse_args()
    device = torch.device(opt.device)
    config = OmegaConf.load(opt.config)
    model = load_model_from_config(config, opt.ckpt, device)
    sampler = DPMSolverSampler(model)

    print(f"ğŸ¨ Generating clean cover image with prompt: '{opt.prompt}'...")
    
    c = model.get_learned_conditioning([opt.prompt])
    uc = model.get_learned_conditioning([""])
    
    torch.manual_seed(opt.secret_key)
    shape = (4, 64, 64)
    
    with torch.no_grad(), autocast("cuda"):
        z_clean, _ = sampler.sample(
            steps=20, conditioning=c, batch_size=1, shape=shape,
            unconditional_guidance_scale=7.5, unconditional_conditioning=uc, verbose=False
        )
    
    z_target_img = z_clean.detach().clone()
    
    capacity = 16384
    secret_bits = get_secret_message(opt.payload_path, opt.secret_key, capacity).to(device)
    
    rng = torch.Generator(device=device).manual_seed(opt.secret_key)
    perm = torch.randperm(capacity, generator=rng, device=device)
    
    z_stego = z_clean.detach().clone().requires_grad_(True)
    optimizer = torch.optim.Adam([z_stego], lr=opt.lr)
    
    print(f"ğŸš€ Starting Gradient Descent Optimization for {opt.opt_iters} steps...")
    print(f"   Configs: lambda_img={opt.lambda_img}, lambda_msg={opt.lambda_msg}, lr={opt.lr}")

    # ä½¿ç”¨ BCEWithLogitsLoss æé«˜æ•¸å€¼ç©©å®šæ€§
    criterion_msg = torch.nn.BCEWithLogitsLoss()

    for i in range(opt.opt_iters):
        optimizer.zero_grad()
        
        # Robustness: åŠ å…¥å™ªè²
        noise_std = 0.1
        noise = torch.randn_like(z_stego) * noise_std
        z_noisy = z_stego + noise
        
        z_flat = z_noisy.view(-1)
        z_shuffled = z_flat[perm]
        
        # === é—œéµä¿®æ­£ï¼šè§£æ±ºæ¢¯åº¦æ¶ˆå¤± ===
        # ä¸è¦ä¹˜ä¸Š 10.0ï¼Œæ”¹ä¹˜ 2.0 æˆ– 1.0ã€‚
        # é€™æ¨£åˆå§‹æ¢¯åº¦ä¸æœƒæ˜¯ 0ï¼Œå„ªåŒ–å™¨æ‰èƒ½å·¥ä½œã€‚
        logits = z_shuffled * 2.0 
        
        loss_msg = criterion_msg(logits, secret_bits)
        loss_img = F.mse_loss(z_stego, z_target_img)
        
        loss = opt.lambda_msg * loss_msg + opt.lambda_img * loss_img
        
        loss.backward()
        optimizer.step()
        
        if i % 50 == 0:
            with torch.no_grad():
                # é©—è­‰æ™‚ä½¿ç”¨ç¡¬åˆ¤æ±º (>0 ç‚º 1)
                pred_bits_hard = (z_shuffled > 0).float()
                acc = (pred_bits_hard == secret_bits).float().mean() * 100
                
                # ç›£æ§æ¢¯åº¦çš„æµå‘ï¼šå¦‚æœ Msg Loss ä¸‹é™ï¼Œä»£è¡¨æœ‰æ•ˆ
                print(f"Step {i:03d} | Loss: {loss.item():.4f} (Msg: {loss_msg.item():.4f}, Img: {loss_img.item():.4f}) | Acc: {acc:.2f}%")

    with torch.no_grad(), autocast("cuda"):
        x_samples = model.decode_first_stage(z_stego)
        x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)
        img_np = (x_samples.cpu().numpy()[0].transpose(1, 2, 0) * 255).astype(np.uint8)
        Image.fromarray(img_np).save(opt.outpath)
        
    print(f"âœ… Generated Stego Image: {opt.outpath}")
    
    gt_bits_path = opt.outpath + ".gt_bits.npy"
    np.save(gt_bits_path, secret_bits.cpu().numpy().astype(np.uint8))
    print(f"ğŸ“„ Saved GT bits to {gt_bits_path}")

if __name__ == "__main__":
    main()