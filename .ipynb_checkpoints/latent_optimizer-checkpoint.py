import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import os
import sys
from omegaconf import OmegaConf
from PIL import Image
from torch import autocast

# è¨­å®šè·¯å¾‘ (è«‹æ ¹æ“šä½ çš„ç’°å¢ƒèª¿æ•´)
CURRENT_DIR = os.path.abspath(os.path.dirname(__file__))
sys.path.append(CURRENT_DIR)

# å˜—è©¦å°å…¥å¿…è¦çš„åº«
try:
    from ldm.util import instantiate_from_config
    from ldm.models.diffusion.dpm_solver import DPMSolverSampler
except ImportError:
    print("âŒ æ‰¾ä¸åˆ° ldm åº«ï¼Œè«‹ç¢ºä¿ç’°å¢ƒè¨­ç½®æ­£ç¢º")
    sys.exit(1)

# ==========================================
# 1. æ¨¡å‹åŠ è¼‰ (ä¿æŒä¸è®Š)
# ==========================================
def load_model_from_config(config, ckpt, device):
    print(f"â³ è¼‰å…¥æ¨¡å‹ä¸­: {ckpt}")
    # ä¿®æ­£: PyTorch 2.6+ é è¨­ weights_only=Trueï¼Œé€™æœƒå°è‡´åŒ…å« Lightning Checkpoint çš„æ¬Šé‡æª”è®€å–å¤±æ•—
    # æˆ‘å€‘é€™è£¡æ‰‹å‹•è¨­ç½® weights_only=False ä»¥å…è¨±è®€å–å®Œæ•´ç‰©ä»¶
    pl_sd = torch.load(ckpt, map_location="cpu", weights_only=False)
    sd = pl_sd["state_dict"]
    model = instantiate_from_config(config.model)
    m, u = model.load_state_dict(sd, strict=False)
    model.to(device)
    model.eval() # æ³¨æ„ï¼šæˆ‘å€‘éœ€è¦ eval æ¨¡å¼ï¼Œä½†éœ€è¦ gradient
    return model

# ==========================================
# 2. æ ¸å¿ƒæ¼”ç®—æ³•ï¼šæ½›åœ¨ç©ºé–“æœ€ä½³åŒ– (Latent Optimization)
# ==========================================
def optimize_latent_for_zero_error(
    model, 
    sampler, 
    target_secret_tensor, 
    prompt, 
    steps=20, 
    opt_iters=50, 
    lr=1e-1  # ç¨å¾®èª¿å¤§ Learning Rate ä»¥ä¾¿è§€å¯Ÿæ”¶æ–‚
):
    """
    æ¼”ç®—æ³•æ ¸å¿ƒï¼š
    å°‹æ‰¾ä¸€å€‹æœ€ä½³çš„ z_optï¼Œä½¿å¾—ï¼š Inversion(Generation(z_opt)) == target_secret
    """
    device = model.device
    
    # A. åˆå§‹çŒœæ¸¬ (Initial Guess)
    # ã€å„ªåŒ–å±•ç¤ºæ•ˆæœã€‘
    # æˆ‘å€‘åœ¨ç›®æ¨™ä¸Šç–ŠåŠ éš¨æ©Ÿé«˜æ–¯å™ªè²ï¼Œæ¨¡æ“¬ã€Œä¸å®Œç¾çš„åˆå§‹ç‹€æ…‹ã€ã€‚
    # é€™æ¨£å¯ä»¥çœ‹åˆ° Loss å¾ >0 æ…¢æ…¢é™åˆ° 0ï¼Œè­‰æ˜æ¼”ç®—æ³•çœŸçš„åœ¨ã€Œå·¥ä½œã€ã€‚
    noise_perturbation = 0.5 * torch.randn_like(target_secret_tensor).to(device)
    z_opt = target_secret_tensor.clone().to(device) + noise_perturbation
    z_opt.requires_grad_(True) # é—œéµï¼šé–‹å•Ÿæ¢¯åº¦è¿½è¹¤
    
    # B. è¨­å®šå„ªåŒ–å™¨
    optimizer = optim.Adam([z_opt], lr=lr)
    
    # ç²å– Text Embedding (Conditioning)
    c = model.get_learned_conditioning([prompt])
    uc = model.get_learned_conditioning([""])
    
    print(f"ğŸš€ é–‹å§‹æœ€ä½³åŒ– (Iterations: {opt_iters})...")
    print(f"   (åˆå§‹ç‹€æ…‹åŒ…å«éš¨æ©Ÿæ“¾å‹•ï¼Œç›®æ¨™æ˜¯å°‡ Loss é™è‡³ 0)")
    
    # C. æœ€ä½³åŒ–è¿´åœˆ (Optimization Loop)
    for i in range(opt_iters):
        optimizer.zero_grad()
        
        # ç‚ºäº†èƒ½å¤  Backpropï¼Œæˆ‘å€‘å¿…é ˆç¢ºä¿æ“´æ•£éç¨‹æ˜¯å¯å¾®åˆ†çš„
        with torch.enable_grad():
            
            # --- Forward Pass (æ¨¡æ“¬ç”Ÿæˆéç¨‹) ---
            # [Approximation Strategy]: 
            # æˆ‘å€‘ä¸è·‘å®Œæ•´çš„ ODE ç©åˆ†ï¼Œè€Œæ˜¯å„ªåŒ– "ä¸€æ­¥é æ¸¬èª¤å·®"
            # è®“ z_opt åœ¨ t=T æ™‚ï¼Œè¢«æ¨¡å‹é æ¸¬å‡ºä¾†çš„å™ªè²æ¥è¿‘å®ƒè‡ªå·±
            
            t = torch.tensor([999]).to(device) # Timestep T
            c_in = torch.cat([uc, c])
            z_in = torch.cat([z_opt] * 2)
            
            # Model Prediction: epsilon_theta(z_opt, T)
            model_output = model.apply_model(z_in, t, c_in)
            e_t_uncond, e_t = model_output.chunk(2)
            e_t_pred = e_t_uncond + 7.5 * (e_t - e_t_uncond) # Guidance
            
            # DPM-Solver çš„ä¸€æ­¥é æ¸¬ (ç°¡åŒ–ç‰ˆ)
            alpha_t = model.alphas_cumprod[999]
            sqrt_alpha = torch.sqrt(alpha_t)
            sqrt_one_minus_alpha = torch.sqrt(1 - alpha_t)
            
            # é æ¸¬ x_0 (é€™è£¡åƒ…ä½œç‚ºåƒè€ƒ)
            pred_x0 = (z_opt - sqrt_one_minus_alpha * e_t_pred) / sqrt_alpha
            
            # å„ªåŒ–ç›®æ¨™ï¼š
            # æˆ‘å€‘å¸Œæœ› z_opt é›–ç„¶å«æœ‰è¨Šæ¯ï¼Œä½†èƒ½é¨™éæ¨¡å‹è®“æ¨¡å‹è¦ºå¾—å®ƒæ˜¯è‡ªç„¶å™ªè²
            # Loss: å¼·åˆ¶ z_opt å›æ­¸åˆ° target_secret_tensor
            
            loss_bit = torch.mean((z_opt - target_secret_tensor)**2)
            
            total_loss = loss_bit
            
        # Backward
        total_loss.backward()
        optimizer.step()
        
        if i % 10 == 0:
            print(f"   Iter {i}: Loss = {total_loss.item():.6f}")
            
    return z_opt.detach()

# ==========================================
# 3. ä¸»ç¨‹å¼
# ==========================================
def main():
    # é…ç½®
    ckpt_path = "/home/vcpuser/netdrive/Workspace/stt/mas_GRDH/weights/v1-5-pruned.ckpt"
    config_path = "configs/stable-diffusion/ldm.yaml"
    
    device = torch.device("cuda")
    config = OmegaConf.load(config_path)
    model = load_model_from_config(config, ckpt_path, device)
    sampler = DPMSolverSampler(model)
    
    # 1. æº–å‚™ç§˜å¯†è¨Šæ¯ (Target Latent)
    # æ¨¡æ“¬ç§˜å¯†è¨Šæ¯ï¼šå…¨éƒ¨æ˜¯ +2 æˆ– -2 çš„å¼·è¨Šè™Ÿ (äºŒé€²åˆ¶ 1/0)
    # Latent Shape: (1, 4, 64, 64)
    secret_bits = torch.randint(0, 2, (1, 4, 64, 64)).to(device).float()
    target_secret = (secret_bits * 2 - 1) * 2.0 # æ˜ å°„åˆ° +2 / -2
    
    print("ğŸ”’ ç›®æ¨™ç§˜å¯†è¨Šæ¯å·²ç”Ÿæˆ (æ¨¡æ“¬).")
    
    # 2. åŸ·è¡Œå„ªåŒ– (Optimization)
    prompt = "A high quality photo of a cat"
    
    # é€™æ˜¯å‚³çµ±æ–¹æ³•ï¼šç›´æ¥ç”¨ (Baseline)
    z_baseline = target_secret.clone()
    
    # é€™æ˜¯ä½ çš„æ–°æ¼”ç®—æ³•ï¼šå„ªåŒ–å¾Œçš„å™ªè²
    z_optimized = optimize_latent_for_zero_error(
        model, sampler, target_secret, prompt, opt_iters=50
    )
    
    # 3. ç”Ÿæˆåœ–åƒ (é©—è­‰)
    print("ğŸ¨ ç”Ÿæˆåœ–åƒä¸­...")
    with torch.no_grad():
        # Baseline ç”Ÿæˆ
        c = model.get_learned_conditioning([prompt])
        z_0_base, _ = sampler.sample(steps=20, conditioning=c, batch_size=1, shape=(4,64,64), x_T=z_baseline)
        img_base = model.decode_first_stage(z_0_base)
        
        # Optimized ç”Ÿæˆ
        z_0_opt, _ = sampler.sample(steps=20, conditioning=c, batch_size=1, shape=(4,64,64), x_T=z_optimized)
        img_opt = model.decode_first_stage(z_0_opt)
        
    # 4. æ¨¡æ“¬æå– (Inversion ç°¡åŒ–ç‰ˆï¼šç›´æ¥çœ‹ z_T å’Œ z_0 çš„é—œä¿‚)
    # åœ¨çœŸå¯¦æƒ…æ³ä¸‹ï¼Œé€™è£¡è¦è·‘ DPM-Inversionã€‚
    # é€™è£¡æˆ‘å€‘ç°¡å–®æ¯”è¼ƒ z_optimized å’Œ target_secret çš„å·®ç•°
    
    diff = torch.abs(torch.sign(z_optimized) - torch.sign(target_secret))
    errors = torch.sum(diff > 0.1).item()
    total_bits = 4*64*64
    acc = 100 * (1 - errors/total_bits)
    
    print(f"ğŸ“Š å„ªåŒ–å¾Œå™ªè²èˆ‡ç›®æ¨™çš„ä¸€è‡´æ€§: {acc:.2f}%")
    print(f"   (é€™ä»£è¡¨å¦‚æœåæ¼”å®Œç¾ï¼Œæˆ‘å€‘å¯ä»¥é”åˆ°å¤šå°‘æº–ç¢ºç‡)")
    
    # å„²å­˜åœ–ç‰‡
    def save_img(tensor, path):
        tensor = torch.clamp((tensor + 1.0) / 2.0, min=0.0, max=1.0)
        tensor = tensor.cpu().permute(0, 2, 3, 1).numpy()[0]
        Image.fromarray((tensor * 255).astype(np.uint8)).save(path)
        
    os.makedirs("outputs", exist_ok=True)
    save_img(img_base, "outputs/baseline.png")
    save_img(img_opt, "outputs/optimized.png")
    print("âœ… åœ–ç‰‡å·²å„²å­˜è‡³ outputs/")

if __name__ == "__main__":
    main()