import sys
import os
import torch
import torch.fft
import numpy as np
from omegaconf import OmegaConf
from torch import autocast
from tqdm import tqdm
import json
import random

# === è·¯å¾‘è¨­å®š ===
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(CURRENT_DIR)
sys.path.append(os.path.join(CURRENT_DIR, "scripts"))

try:
    from ldm.util import instantiate_from_config
    from ldm.models.diffusion.dpm_solver import DPMSolverSampler
except ImportError:
    pass 

# === è¨­å®š ===
MAS_GRDH_PATH = CURRENT_DIR
CKPT_PATH = os.path.join(MAS_GRDH_PATH, "weights/v1-5-pruned.ckpt")
CONFIG_PATH = os.path.join(MAS_GRDH_PATH, "configs/stable-diffusion/ldm.yaml")
DIR_CAPTIONS = os.path.join(CURRENT_DIR, "scripts/coco_annotations", "captions_val2017.json")
TOTAL_SAMPLES = 1000 # æ ¡æº–æ¨£æœ¬æ•¸

def load_model_from_config(config, ckpt, device):
    print(f"Loading model from {ckpt}...")
    pl_sd = torch.load(ckpt, map_location="cpu", weights_only=False)
    sd = pl_sd["state_dict"] if "state_dict" in pl_sd else pl_sd
    model = instantiate_from_config(config.model)
    model.load_state_dict(sd, strict=False)
    model.to(device)
    model.eval()
    return model

def calculate_low_freq_ratio(z_latent):
    """è¨ˆç®—å–®å¼µ Latent çš„ä½é »ä½”æ¯”"""
    freq_domain = torch.fft.fftn(z_latent, dim=(-2, -1))
    energy = torch.abs(freq_domain)
    
    h, w = energy.shape[-2:]
    h_center, w_center = h // 2, w // 2
    r_h, r_w = h // 4, w // 4 
    
    total_energy = torch.sum(energy)
    energy_shifted = torch.fft.fftshift(energy, dim=(-2, -1))
    low_freq_energy = torch.sum(energy_shifted[..., h_center-r_h:h_center+r_h, w_center-r_w:w_center+r_w])
    
    return (low_freq_energy / (total_energy + 1e-8)).item()

def main():
    print(f"ğŸš€ Starting Spectral Ratio Calibration (N={TOTAL_SAMPLES})...")
    
    device = torch.device("cuda")
    config = OmegaConf.load(CONFIG_PATH)
    model = load_model_from_config(config, CKPT_PATH, device)
    sampler = DPMSolverSampler(model)

    # è¼‰å…¥ Prompts
    with open(DIR_CAPTIONS, 'r') as f:
        data = json.load(f)
    captions = [item['caption'] for item in data['annotations']]
    random.shuffle(captions)
    prompts = captions[:TOTAL_SAMPLES]

    ratios = []
    
    print("running sampling...")
    with torch.no_grad(), autocast("cuda"):
        for prompt in tqdm(prompts):
            # 1. æº–å‚™æ¢ä»¶
            c = model.get_learned_conditioning([prompt])
            uc = model.get_learned_conditioning([""])
            
            # 2. æ¨¡æ“¬ z_target (éš¨æ©Ÿå™ªè²å³å¯ï¼Œå› ç‚ºé‡é»æ˜¯ prompt æ±ºå®šçš„ z_0)
            z_center = torch.randn(1, 4, 64, 64, device=device)
            
            # 3. åŠ å…¥å¾®å°æ“¾å‹• (æ¨¡æ“¬ estimate_uncertainty çš„è¡Œç‚º)
            noise = torch.randn_like(z_center) * 0.05
            z_input = z_center + noise
            
            # 4. å¿«é€Ÿæ¡æ¨£ (åªè·‘ä¸€æ¬¡ DPM Encode å¾—åˆ° z_0)
            # æˆ‘å€‘åªéœ€è¦ z_0 çš„é »è­œï¼Œä¸éœ€è¦å¾Œé¢çš„åæ¼”
            z_0, _ = sampler.sample(steps=10, conditioning=c, batch_size=1, shape=(4, 64, 64),
                                    unconditional_guidance_scale=5.0, unconditional_conditioning=uc,
                                    x_T=z_input, DPMencode=False, DPMdecode=True, verbose=False)
            
            # 5. è¨ˆç®— Ratio
            ratio = calculate_low_freq_ratio(z_0)
            ratios.append(ratio)

    # === çµ±è¨ˆçµæœ ===
    ratios = np.array(ratios)
    mean_ratio = np.mean(ratios)
    std_ratio = np.std(ratios)
    min_ratio = np.min(ratios)
    max_ratio = np.max(ratios)

    print("\n" + "="*50)
    print("ğŸ“Š Calibration Result (COCO Validation)")
    print("-" * 50)
    print(f"Count: {len(ratios)}")
    print(f"Mean Ratio (Target): {mean_ratio:.4f}")
    print(f"Std Dev: {std_ratio:.4f}")
    print(f"Min / Max: {min_ratio:.4f} / {max_ratio:.4f}")
    print("="*50)
    
    print(f"\nğŸ’¡ [Action] Please update 'target_mean_ratio' in 'pure_alice_spectral_mask.py' to: {mean_ratio:.4f}")

if __name__ == "__main__":
    main()