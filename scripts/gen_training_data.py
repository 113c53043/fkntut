# æª”æ¡ˆä½ç½®: scripts/gen_training_data.py
import os
import sys
import torch
import numpy as np
from PIL import Image
from omegaconf import OmegaConf
from torch import autocast
from tqdm import tqdm

# è·¯å¾‘è¨­å®š
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.dirname(CURRENT_DIR)) # åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„

# å°å…¥æ‚¨çš„æ¨¡çµ„
try:
    from ldm.util import instantiate_from_config
    from ldm.models.diffusion.dpm_solver import DPMSolverSampler
    import mapping_module 
except ImportError as e:
    print(f"âŒ å°å…¥å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿æ‚¨åœ¨ mas_GRDH/scripts ç›®éŒ„ä¸‹ï¼Œä¸”ä¸Šä¸€å±¤ç›®éŒ„åŒ…å« ldm å’Œ mapping_module")
    sys.exit(1)

# === è¨­å®š ===
# è«‹æ ¹æ“šæ‚¨çš„ç’°å¢ƒä¿®æ”¹ä»¥ä¸‹è·¯å¾‘
CKPT_PATH = "/home/vcpuser/netdrive/Workspace/st/mas_GRDH/weights/v1-5-pruned.ckpt"
CONFIG_PATH = os.path.join(os.path.dirname(CURRENT_DIR), "configs/stable-diffusion/ldm.yaml")
OUTPUT_ROOT = os.path.join(os.path.dirname(CURRENT_DIR), "training_data")

# ã€ä¿®æ”¹é» 1ã€‘ç”Ÿæˆæ•¸é‡æ“´å……åˆ° 10,000 å° (å…± 20,000 å¼µåœ–)
NUM_SAMPLES = 5000 
PROMPTS = ["A photo of a landscape", "A cute cat", "A futuristic city", "Delicious food", "Abstract art"]

def load_model(config_path, ckpt_path, device):
    config = OmegaConf.load(config_path)
    # åŠ å…¥ weights_only=False ä»¥è§£æ±º PyTorch 2.6+ çš„ååºåˆ—åŒ–éŒ¯èª¤
    pl_sd = torch.load(ckpt_path, map_location="cpu", weights_only=False)
    sd = pl_sd["state_dict"]
    model = instantiate_from_config(config.model)
    model.load_state_dict(sd, strict=False)
    model.to(device)
    model.eval()
    return model

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[System] ä½¿ç”¨è¨­å‚™: {device}")
    
    if not os.path.exists(CKPT_PATH):
        print(f"âŒ æ‰¾ä¸åˆ°æ¬Šé‡æª”: {CKPT_PATH}")
        return

    model = load_model(CONFIG_PATH, CKPT_PATH, device)
    sampler = DPMSolverSampler(model)
    mapper = mapping_module.ours_mapping(bits=1) # å‡è¨­ bit_num=1

    # å»ºç«‹è³‡æ–™å¤¾
    os.makedirs(os.path.join(OUTPUT_ROOT, "cover"), exist_ok=True)
    os.makedirs(os.path.join(OUTPUT_ROOT, "stego"), exist_ok=True)

    print(f"ğŸš€ é–‹å§‹ç”Ÿæˆè¨“ç·´æ•¸æ“š (ç›®æ¨™: {NUM_SAMPLES} å°)...")
    print(f"ğŸ“ è¼¸å‡ºä½ç½®: {OUTPUT_ROOT}")

    # ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦
    for i in tqdm(range(NUM_SAMPLES), desc="Generating"):
        # ã€ä¿®æ”¹é» 2ã€‘ä¸­æ–·çºŒå‚³æ©Ÿåˆ¶ï¼šæª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
        cover_filename = f"{i:05d}.png"
        cover_path = os.path.join(OUTPUT_ROOT, "cover", cover_filename)
        stego_path = os.path.join(OUTPUT_ROOT, "stego", cover_filename)

        if os.path.exists(cover_path) and os.path.exists(stego_path):
            # å¦‚æœå…©å¼µåœ–éƒ½å·²ç¶“å­˜åœ¨ï¼Œå°±è·³éä¸é‡æ–°ç”Ÿæˆ
            continue

        prompt = np.random.choice(PROMPTS)
        seed = np.random.randint(0, 1000000)
        
        # 1. æº–å‚™æ¢ä»¶
        c = model.get_learned_conditioning([prompt])
        uc = model.get_learned_conditioning([""])
        shape = (4, 512 // 8, 512 // 8)
        
        # === ç”Ÿæˆ Cover (éš¨æ©Ÿå™ªè²) ===
        np.random.seed(seed)
        noise_cover = torch.randn(1, *shape).to(device)
        
        with torch.no_grad(), autocast("cuda"):
            z_0_cover, _ = sampler.sample(
                steps=20, conditioning=c, batch_size=1, shape=shape,
                unconditional_guidance_scale=5.0, unconditional_conditioning=uc,
                x_T=noise_cover
            )
            x_cover = model.decode_first_stage(z_0_cover)
            x_cover = torch.clamp((x_cover + 1.0) / 2.0, min=0.0, max=1.0)
        
        # ä¿å­˜ Cover
        img_cover = Image.fromarray((x_cover[0].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8))
        img_cover.save(cover_path)

        # === ç”Ÿæˆ Stego (éš±å¯«å™ªè²) ===
        seed_key = np.random.randint(0, 999999)
        # å‡è¨­ latent shape æ˜¯ (1, 4, 64, 64)
        secret_msg = np.random.randint(0, 2, (1, 4, 64, 64)) 
        
        # èª¿ç”¨æ˜ å°„å‡½æ•¸
        # æ³¨æ„ï¼šé€™è£¡ noise base æœ€å¥½ä¹Ÿå›ºå®š seed æˆ–èˆ‡ cover ä¿æŒæŸç¨®é—œä¿‚ï¼Œè¦–æ‚¨çš„æ¼”ç®—æ³•é‚è¼¯è€Œå®š
        # é€™è£¡ç¶­æŒåŸæ¨£ï¼š
        z_stego_np = mapper.encode_secret(
            secret_message=secret_msg, 
            ori_sample=np.random.randn(1, 4, 64, 64), 
            seed_kernel=seed_key, 
            seed_shuffle=seed_key+123
        )
        noise_stego = torch.from_numpy(z_stego_np).float().to(device)
        
        with torch.no_grad(), autocast("cuda"):
            z_0_stego, _ = sampler.sample(
                steps=20, conditioning=c, batch_size=1, shape=shape,
                unconditional_guidance_scale=5.0, unconditional_conditioning=uc,
                x_T=noise_stego
            )
            x_stego = model.decode_first_stage(z_0_stego)
            x_stego = torch.clamp((x_stego + 1.0) / 2.0, min=0.0, max=1.0)

        # ä¿å­˜ Stego
        img_stego = Image.fromarray((x_stego[0].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8))
        img_stego.save(stego_path)

        # ã€ä¿®æ”¹é» 3ã€‘å®šæœŸæ¸…ç† Cache (æ¯ 100 å¼µæ¸…ç†ä¸€æ¬¡ï¼Œé˜²æ­¢ OOM)
        if i % 100 == 0:
            torch.cuda.empty_cache()

    print(f"âœ… 10,000 å°æ•¸æ“šç”Ÿæˆå®Œæˆï¼è«‹æª¢æŸ¥ {OUTPUT_ROOT}")

if __name__ == "__main__":
    main()